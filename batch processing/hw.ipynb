{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/03/02 16:41:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Version : 3.3.2\n"
     ]
    }
   ],
   "source": [
    "print(f'Spark Version : {spark.version}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv('./data/fhv_tripdata_2019-10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('dispatching_base_num', StringType(), True), StructField('pickup_datetime', StringType(), True), StructField('dropOff_datetime', StringType(), True), StructField('PUlocationID', StringType(), True), StructField('DOlocationID', StringType(), True), StructField('SR_Flag', StringType(), True), StructField('Affiliated_base_number', StringType(), True)])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 1001 ./data/fhv_tripdata_2019-10.csv > head.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas = pd.read_csv('head.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dispatching_base_num       object\n",
       "pickup_datetime            object\n",
       "dropOff_datetime           object\n",
       "PUlocationID              float64\n",
       "DOlocationID              float64\n",
       "SR_Flag                   float64\n",
       "Affiliated_base_number     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pandas.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = types.StructType([\n",
    "    types.StructField('dispatching_base_num', types.StringType(), True),\n",
    "    types.StructField('pickup_datetime', types.TimestampType(), True),\n",
    "    types.StructField('dropoff_datetime', types.TimestampType(), True),\n",
    "    types.StructField('PULocationID', types.IntegerType(), True),\n",
    "    types.StructField('DOLocationID', types.IntegerType(), True),\n",
    "    types.StructField('SR_Flag', types.StringType(), True),\n",
    "    types.StructField('Affiliated_base_number', types.StringType(), True),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(schema) \\\n",
    "    .csv('./data/fhv_tripdata_2019-10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.mode('overwrite').parquet('./data/parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet('./data/parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- SR_Flag: string (nullable = true)\n",
      " |-- Affiliated_base_number: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|Affiliated_base_number|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|              B02784|2019-10-01 09:55:38|2019-10-01 10:05:43|          89|          85|   null|                  null|\n",
      "|              B01315|2019-10-05 15:13:04|2019-10-05 15:19:48|         264|          74|   null|                B01315|\n",
      "|              B01984|2019-10-12 17:13:00|2019-10-12 17:40:00|         264|          75|   null|                B01984|\n",
      "|              B00310|2019-10-15 10:55:04|2019-10-15 11:00:45|         264|         247|   null|                B03047|\n",
      "|              B00932|2019-10-08 06:58:42|2019-10-08 07:11:11|         264|          37|   null|                B00932|\n",
      "|              B01029|2019-10-10 14:45:00|2019-10-10 15:47:00|         264|         264|   null|                B01029|\n",
      "|              B01087|2019-10-14 18:41:24|2019-10-14 19:02:06|         261|         186|   null|                B01087|\n",
      "|              B03080|2019-10-05 14:49:10|2019-10-05 15:02:14|         264|          25|   null|                B02889|\n",
      "|              B03160|2019-10-10 12:50:00|2019-10-10 13:34:00|          77|          77|   null|                B02882|\n",
      "|              B02472|2019-10-16 14:12:36|2019-10-16 14:35:00|         264|         157|   null|                B02472|\n",
      "|              B01051|2019-10-05 22:06:46|2019-10-05 22:16:57|         264|         182|   null|                B01051|\n",
      "|              B02111|2019-10-08 14:58:52|2019-10-08 15:40:41|          98|          79|   null|                B02111|\n",
      "|              B00254|2019-10-03 20:33:11|2019-10-03 21:52:16|         246|         265|   null|                B02356|\n",
      "|              B00756|2019-10-16 10:58:00|2019-10-16 11:18:00|         264|         264|   null|                B00756|\n",
      "|              B02249|2019-10-04 19:55:49|2019-10-04 20:08:25|         264|         192|   null|                B02249|\n",
      "|              B03202|2019-10-13 07:39:33|2019-10-13 08:18:31|         264|         132|   null|                B03202|\n",
      "|              B00419|2019-10-11 08:33:12|2019-10-11 08:46:22|         182|         185|   null|                B00419|\n",
      "|              B02095|2019-10-09 11:16:00|2019-10-09 11:44:00|         264|         264|   null|                B02095|\n",
      "|              B02930|2019-10-05 22:06:15|2019-10-05 22:25:31|         264|          69|   null|                B02930|\n",
      "|              B01239|2019-10-07 20:08:15|2019-10-07 20:16:06|         264|          51|   null|                B02847|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.registerTempTable('trips_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|total_trips|\n",
      "+-----------+\n",
      "|      62610|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    count(*) AS total_trips\n",
    "FROM\n",
    "    trips_data\n",
    "WHERE pickup_datetime BETWEEN '2019-10-15 00:00:00' AND '2019-10-15 23:59:59'\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 40:>                                                         (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+-------------+------------------+\n",
      "|dispatching_base_num|pickup_datetime    |dropoff_datetime   |PULocationID|DOLocationID|SR_Flag|Affiliated_base_number|DiffInSeconds|DiffInHours       |\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+-------------+------------------+\n",
      "|B02832              |2019-10-11 18:00:00|2091-10-11 18:30:00|264         |264         |null   |B02832                |2272149000   |631152.5          |\n",
      "|B02832              |2019-10-28 09:00:00|2091-10-28 09:30:00|264         |264         |null   |B02832                |2272149000   |631152.5          |\n",
      "|B02416              |2019-10-31 23:46:33|2029-11-01 00:13:00|null        |null        |null   |B02416                |315620787    |87672.44083333333 |\n",
      "|B00746              |2019-10-01 21:43:42|2027-10-01 21:45:23|159         |264         |null   |B00746                |252460901    |70128.02805555555 |\n",
      "|B02921              |2019-10-17 14:00:00|2020-10-18 00:00:00|null        |null        |null   |B03037                |31658400     |8794.0            |\n",
      "|B03110              |2019-10-26 21:26:00|2020-10-26 21:36:00|264         |264         |null   |B03110                |31623000     |8784.166666666666 |\n",
      "|B03080              |2019-10-30 12:30:04|2019-12-30 13:02:08|264         |50          |null   |B02883                |5272324      |1464.5344444444445|\n",
      "|B03084              |2019-10-25 07:04:57|2019-12-08 07:54:33|168         |235         |null   |B02765                |3804576      |1056.8266666666666|\n",
      "|B03084              |2019-10-25 07:04:57|2019-12-08 07:21:11|168         |235         |null   |B02765                |3802574      |1056.2705555555556|\n",
      "|B01452              |2019-10-01 13:47:17|2019-11-03 15:20:28|44          |214         |null   |B01452                |2856791      |793.5530555555556 |\n",
      "|B01452              |2019-10-01 07:21:12|2019-11-03 08:44:21|5           |6           |null   |B01452                |2856189      |793.3858333333334 |\n",
      "|B01452              |2019-10-01 13:41:00|2019-11-03 14:58:51|206         |172         |null   |B01452                |2855871      |793.2975          |\n",
      "|B01452              |2019-10-01 18:43:20|2019-11-03 19:43:13|23          |5           |null   |B01452                |2854793      |792.9980555555555 |\n",
      "|B01452              |2019-10-01 18:43:46|2019-11-03 19:43:04|251         |44          |null   |B01452                |2854758      |792.9883333333333 |\n",
      "|B01452              |2019-10-01 07:07:09|2019-11-03 07:58:46|204         |23          |null   |B01452                |2854297      |792.8602777777778 |\n",
      "|B01452              |2019-10-01 14:49:28|2019-11-03 15:38:07|214         |156         |null   |B01452                |2854119      |792.8108333333333 |\n",
      "|B01452              |2019-10-01 05:36:30|2019-11-03 06:23:36|214         |84          |null   |B01452                |2854026      |792.785           |\n",
      "|B00972              |2019-10-01 15:02:55|2019-11-03 15:49:05|204         |1           |null   |B00972                |2853970      |792.7694444444444 |\n",
      "|B00972              |2019-10-01 06:08:01|2019-11-03 06:53:15|156         |204         |null   |B00972                |2853914      |792.7538888888889 |\n",
      "|B01452              |2019-10-01 06:41:17|2019-11-03 07:26:04|44          |23          |null   |B01452                |2853887      |792.7463888888889 |\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+-------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.withColumn('DiffInSeconds',unix_timestamp(\"dropoff_datetime\") - unix_timestamp('pickup_datetime')) \\\n",
    "    .withColumn('DiffInHours', col('DiffInSeconds')/3600) \\\n",
    "    .sort('DiffInSeconds', ascending=False) \\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv('./data/taxi+_zone_lookup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+-----------------------+------------+\n",
      "|LocationID|Borough      |Zone                   |service_zone|\n",
      "+----------+-------------+-----------------------+------------+\n",
      "|1         |EWR          |Newark Airport         |EWR         |\n",
      "|2         |Queens       |Jamaica Bay            |Boro Zone   |\n",
      "|3         |Bronx        |Allerton/Pelham Gardens|Boro Zone   |\n",
      "|4         |Manhattan    |Alphabet City          |Yellow Zone |\n",
      "|5         |Staten Island|Arden Heights          |Boro Zone   |\n",
      "|6         |Staten Island|Arrochar/Fort Wadsworth|Boro Zone   |\n",
      "|7         |Queens       |Astoria                |Boro Zone   |\n",
      "|8         |Queens       |Astoria Park           |Boro Zone   |\n",
      "|9         |Queens       |Auburndale             |Boro Zone   |\n",
      "|10        |Queens       |Baisley Park           |Boro Zone   |\n",
      "|11        |Brooklyn     |Bath Beach             |Boro Zone   |\n",
      "|12        |Manhattan    |Battery Park           |Yellow Zone |\n",
      "|13        |Manhattan    |Battery Park City      |Yellow Zone |\n",
      "|14        |Brooklyn     |Bay Ridge              |Boro Zone   |\n",
      "|15        |Queens       |Bay Terrace/Fort Totten|Boro Zone   |\n",
      "|16        |Queens       |Bayside                |Boro Zone   |\n",
      "|17        |Brooklyn     |Bedford                |Boro Zone   |\n",
      "|18        |Bronx        |Bedford Park           |Boro Zone   |\n",
      "|19        |Queens       |Bellerose              |Boro Zone   |\n",
      "|20        |Bronx        |Belmont                |Boro Zone   |\n",
      "+----------+-------------+-----------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_zones.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones.createOrReplaceTempView(\"zones\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 51:>                                                         (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+-----------+\n",
      "|LocationID|                Zone|total_trips|\n",
      "+----------+--------------------+-----------+\n",
      "|         2|         Jamaica Bay|          1|\n",
      "|       105|Governor's Island...|          2|\n",
      "|       111| Green-Wood Cemetery|          5|\n",
      "|        30|       Broad Channel|          8|\n",
      "|       120|     Highbridge Park|         14|\n",
      "|        12|        Battery Park|         15|\n",
      "|       207|Saint Michaels Ce...|         23|\n",
      "|        27|Breezy Point/Fort...|         25|\n",
      "|       154|Marine Park/Floyd...|         26|\n",
      "|         8|        Astoria Park|         29|\n",
      "|       128|    Inwood Hill Park|         39|\n",
      "|       253|       Willets Point|         47|\n",
      "|        96|Forest Park/Highl...|         53|\n",
      "|        34|  Brooklyn Navy Yard|         57|\n",
      "|        59|        Crotona Park|         62|\n",
      "|        58|        Country Club|         77|\n",
      "|        99|     Freshkills Park|         89|\n",
      "|       190|       Prospect Park|         98|\n",
      "|        54|     Columbia Street|        105|\n",
      "|       217|  South Williamsburg|        110|\n",
      "+----------+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    zones.LocationID,\n",
    "    zones.Zone,\n",
    "    COUNT(1) AS total_trips\n",
    "FROM\n",
    "    trips_data\n",
    "INNER JOIN zones\n",
    "    ON trips_data.PULocationID = zones.LocationID\n",
    "GROUP BY zones.LocationID,\n",
    "    zones.Zone\n",
    "ORDER BY total_trips\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
